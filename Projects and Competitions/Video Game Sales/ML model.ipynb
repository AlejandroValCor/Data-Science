{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c1d5ef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import re\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e512d349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize the format for the datasets\n",
    "def normalizeDatasetFormat(dataset):\n",
    "    # 14 most lucrative/popular videogame franchises\n",
    "    topFranchises = [\n",
    "        \"Mario\", \"Tetris\", \"Call of Duty\", \"Pokemon\", \"Grand Theft Auto\",\n",
    "        \"FIFA\", \"Wii\", \"Lego\", \"The Sims\", \"Assassin's Creed\", \"Final Fantasy\",\n",
    "        \"Sonic\", \"Zelda\", \"Resident Evil\"\n",
    "    ]\n",
    "\n",
    "    # Merge all the franchises in one same regex expresion\n",
    "    regex = '|'.join([re.escape(franchise) for franchise in topFranchises])\n",
    "\n",
    "    # Apply the regex to extract the franchise on each title name\n",
    "    dataset['Franchise'] = (\n",
    "        dataset['Name']\n",
    "        .str.extract(f'({regex})', flags=re.IGNORECASE, expand=False)\n",
    "        .fillna('Other')\n",
    "    )\n",
    "\n",
    "    # Normalize franchise name, first upper case rest lower case\n",
    "    dataset['Franchise'] = dataset['Franchise'].str.title()\n",
    "\n",
    "    # Get only the 14 most common platforms\n",
    "    topPlatforms = list(dataset['Platform'].value_counts().nlargest(14).index)\n",
    "    print(topPlatforms)\n",
    "\n",
    "    # Get the 14 most common platforms and for all others assign 'Other' ending with a 15 cardinality.\n",
    "    dataset['PlatformReduced'] = dataset['Platform'].apply(lambda x: x if x in topPlatforms else 'Other')\n",
    "    dataset['PlatformReduced'].value_counts()\n",
    "\n",
    "    # Get only the 14 most common publishers\n",
    "    topPublishers = list(dataset['Publisher'].value_counts().nlargest(14).index)\n",
    "    print(topPublishers)\n",
    "\n",
    "    # Get the 14 most common publishers and for all others assign 'Other' ending with a 15 cardinality.\n",
    "    dataset['PublisherReduced'] = dataset['Publisher'].apply(lambda x: x if x in topPublishers else 'Other')\n",
    "    dataset['PublisherReduced'].value_counts()\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ae76e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to acquire the best parameters for Random Forest Regressor\n",
    "def bestParamsEstimatorRanFor(preprocessor, X_train, y_train):\n",
    "    # Creation of staple model to work with\n",
    "    model = RandomForestRegressor(random_state=0, n_jobs = -1)\n",
    "\n",
    "    # Pipeline creation to use in GridSearchCV\n",
    "    regressor = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # Parameters that are going to be tested during GridSearchCV\n",
    "    param_grid = {\n",
    "        'model__n_estimators': [90, 95, 100, 105, 110],\n",
    "        'model__max_depth': [15, 20, 25]\n",
    "    }\n",
    "        \n",
    "    # Declaration of grid search with parameters, cv = 5 cross validation in 5 splits\n",
    "    grid_search = GridSearchCV(regressor, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "    # Search for the best parameters during the fit of the grid search with the train dataset.\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0a484f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to acquire the best parameters for XGB Regressor (Wrap function to accept parameters)\n",
    "def bestParamsEstimatorXGBR(preprocessor, X_train, y_train):\n",
    "    # Necessary function for optuna\n",
    "    def objective(trial):\n",
    "        # Declaration parameters and ranges for each one that are going to be tested with optuna\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 185, 190),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 5),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.15, 0.2),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'random_state': 0\n",
    "        }\n",
    "\n",
    "        # Declaration of XGBR model to be used with optuna\n",
    "        model = XGBRegressor(**params)\n",
    "\n",
    "        # Pipeline creation to use with optuna\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', model)\n",
    "        ])\n",
    "\n",
    "        # Cross validation scores acquired and mean calculated, needed for optuna to find best parameters.\n",
    "        score = cross_val_score(pipeline, X_train, y_train, cv=10, scoring='neg_mean_squared_error')\n",
    "        return score.mean()\n",
    "    \n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b9c34f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the train dataset \n",
    "X = pd.read_csv('D:/Archivos Personales/Courses/Data Science/Projects and Competitions/Video Game Sales/vgsales.csv')\n",
    "\n",
    "# Remove any rows that may have NaN values in NA_Sales column.\n",
    "X.dropna(axis=0, subset=['NA_Sales'], inplace=True)\n",
    "\n",
    "# Assigning the target column to Y from X\n",
    "Y = X.NA_Sales\n",
    "X.drop(['NA_Sales'], axis=1, inplace=True)\n",
    "\n",
    "# Splitting the dataset into training and validation subsets\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, Y, train_size=0.8, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4266f1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rank              0\n",
       "Name              0\n",
       "Platform          0\n",
       "Year            271\n",
       "Genre             0\n",
       "Publisher        58\n",
       "EU_Sales          0\n",
       "JP_Sales          0\n",
       "Other_Sales       0\n",
       "Global_Sales      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review how many NaN values are per columns, to see if dropping a column can be an option.\n",
    "nanValuesPerColumn = X.isnull().sum()\n",
    "nanValuesPerColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "30a88981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name         9677\n",
       "Platform       30\n",
       "Genre          12\n",
       "Publisher     522\n",
       "dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the categorical values in the dataset and see their cardinality\n",
    "categorical_columns = list(X_train_full.select_dtypes(include=['object']).columns)\n",
    "X_train_full[categorical_columns].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "14c51cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Platform\n",
       "PS2     1758\n",
       "DS      1730\n",
       "Wii     1060\n",
       "PS3     1053\n",
       "X360    1026\n",
       "PSP      962\n",
       "PS       952\n",
       "PC       775\n",
       "XB       663\n",
       "GBA      649\n",
       "GC       448\n",
       "3DS      410\n",
       "PSV      320\n",
       "PS4      264\n",
       "N64      259\n",
       "SNES     185\n",
       "XOne     167\n",
       "SAT      137\n",
       "WiiU     113\n",
       "2600     107\n",
       "NES       80\n",
       "GB        76\n",
       "DC        40\n",
       "GEN       22\n",
       "NG        10\n",
       "SCD        4\n",
       "WS         4\n",
       "3DO        2\n",
       "PCFX       1\n",
       "GG         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyze the quantity for each platform\n",
    "X_train_full['Platform'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "dfcf4ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PS2', 'DS', 'Wii', 'PS3', 'X360', 'PSP', 'PS', 'PC', 'XB', 'GBA', 'GC', '3DS', 'PSV', 'PS4']\n",
      "['Electronic Arts', 'Activision', 'Namco Bandai Games', 'Ubisoft', 'Konami Digital Entertainment', 'THQ', 'Nintendo', 'Sony Computer Entertainment', 'Sega', 'Take-Two Interactive', 'Capcom', 'Atari', 'Tecmo Koei', 'Warner Bros. Interactive Entertainment']\n",
      "['DS', 'PS2', 'PS3', 'Wii', 'PSP', 'PS', 'X360', 'PC', 'GBA', 'XB', 'GC', '3DS', 'PSV', 'PS4']\n",
      "['Electronic Arts', 'Activision', 'Ubisoft', 'Namco Bandai Games', 'Konami Digital Entertainment', 'THQ', 'Nintendo', 'Sony Computer Entertainment', 'Sega', 'Atari', 'Take-Two Interactive', 'Capcom', 'Tecmo Koei', 'Square Enix']\n",
      "['DS', 'PS2', 'PS3', 'Wii', 'X360', 'PSP', 'PS', 'PC', 'XB', 'GBA', 'GC', '3DS', 'PSV', 'PS4']\n",
      "['Electronic Arts', 'Activision', 'Namco Bandai Games', 'Ubisoft', 'Konami Digital Entertainment', 'THQ', 'Nintendo', 'Sony Computer Entertainment', 'Sega', 'Take-Two Interactive', 'Capcom', 'Atari', 'Tecmo Koei', 'Square Enix']\n"
     ]
    }
   ],
   "source": [
    "# Normalize the transformation and data format in all datasets\n",
    "X_train_full = normalizeDatasetFormat(X_train_full)\n",
    "X_valid_full = normalizeDatasetFormat(X_valid_full)\n",
    "X = normalizeDatasetFormat(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "90dd3ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                9677\n",
       "Platform              30\n",
       "Genre                 12\n",
       "Publisher            522\n",
       "Franchise             15\n",
       "PlatformReduced       15\n",
       "PublisherReduced      15\n",
       "dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the categorical values once again but with thew new columns and see their cardinality\n",
    "categorical_columns = list(X_train_full.select_dtypes(include=['object']).columns)\n",
    "X_train_full[categorical_columns].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "cdecbdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final categorical columns: ['Genre', 'Franchise', 'PlatformReduced', 'PublisherReduced']\n",
      "Final numerical columns: ['Rank', 'Year', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales']\n"
     ]
    }
   ],
   "source": [
    "# Variable declaration for final categorical and numerical columns\n",
    "final_categorical_columns = []\n",
    "final_numerical_columns = []\n",
    "\n",
    "# Extract only categorical columns and numerical columns and append them to their respective variables\n",
    "for column in X_train_full.columns:\n",
    "    if X_train_full[column].nunique() < 16 and X_train_full[column].dtype == 'object':\n",
    "        final_categorical_columns.append(column)\n",
    "    elif X_train_full[column].dtype in ['int64', 'float64']:\n",
    "        final_numerical_columns.append(column)\n",
    "\n",
    "print(f\"Final categorical columns: {final_categorical_columns}\\nFinal numerical columns: {final_numerical_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a48365d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Franchise</th>\n",
       "      <th>PlatformReduced</th>\n",
       "      <th>PublisherReduced</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Year</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11199</th>\n",
       "      <td>Action</td>\n",
       "      <td>Lego</td>\n",
       "      <td>GBA</td>\n",
       "      <td>Other</td>\n",
       "      <td>11201</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11648</th>\n",
       "      <td>Misc</td>\n",
       "      <td>Other</td>\n",
       "      <td>PS2</td>\n",
       "      <td>Namco Bandai Games</td>\n",
       "      <td>11650</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14120</th>\n",
       "      <td>Shooter</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>14122</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14933</th>\n",
       "      <td>Strategy</td>\n",
       "      <td>Other</td>\n",
       "      <td>PC</td>\n",
       "      <td>Other</td>\n",
       "      <td>14936</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12119</th>\n",
       "      <td>Sports</td>\n",
       "      <td>Other</td>\n",
       "      <td>GC</td>\n",
       "      <td>Sega</td>\n",
       "      <td>12121</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Genre Franchise PlatformReduced    PublisherReduced   Rank    Year  \\\n",
       "11199    Action      Lego             GBA               Other  11201  2006.0   \n",
       "11648      Misc     Other             PS2  Namco Bandai Games  11650  2009.0   \n",
       "14120   Shooter     Other           Other               Other  14122  1998.0   \n",
       "14933  Strategy     Other              PC               Other  14936  1998.0   \n",
       "12119    Sports     Other              GC                Sega  12121  2002.0   \n",
       "\n",
       "       EU_Sales  JP_Sales  Other_Sales  Global_Sales  \n",
       "11199      0.02      0.00          0.0          0.09  \n",
       "11648      0.00      0.08          0.0          0.08  \n",
       "14120      0.00      0.03          0.0          0.03  \n",
       "14933      0.02      0.00          0.0          0.02  \n",
       "12119      0.01      0.00          0.0          0.07  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final total columns to keep in final version of the datasets\n",
    "myColumns = final_categorical_columns + final_numerical_columns\n",
    "\n",
    "# Normalization of columns for all datasets\n",
    "X_train = X_train_full[myColumns].copy()\n",
    "X_valid = X_valid_full[myColumns].copy()\n",
    "X = X[myColumns].copy()\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "61371a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------Pipeline creation----------------------------------------------------\n",
    "\n",
    "# Creation of the numerical transformer\n",
    "numericalTransformer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Creation of the categorical transformer\n",
    "categoricalTransformer = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "    ('OneHotEnc', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Creation of the preprocessor to use in the pipeline as well as in the best parameters functions\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('numerical', numericalTransformer, final_numerical_columns),\n",
    "    ('categorical', categoricalTransformer, final_categorical_columns)\n",
    "])\n",
    "\n",
    "#bestParamsEstimatorRanFor(preprocessor, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "de13079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters using bestParamsEstimatorRanFor function: {'model__max_depth': 25, 'model__n_estimators': 100}\n",
    "model = RandomForestRegressor(n_estimators=100, max_depth=25, random_state=0) \n",
    "\n",
    "# Pipeline creation with model with best parameters\n",
    "regressor = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Fitting and training model with train dataset\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions for valid dataset with random forest regressor model\n",
    "predictions = regressor.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d7a84695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 89.12%\n",
      "RMSE: 0.2797627174264075\n",
      "MAE: 0.02612368130923189\n"
     ]
    }
   ],
   "source": [
    "# Calculated error metrics for R2, RMSE and MAE\n",
    "rmseRF = np.sqrt(mean_squared_error(y_valid, predictions))\n",
    "maeRF = mean_absolute_error(y_valid, predictions)\n",
    "r2RF = r2_score(y_valid, predictions)\n",
    "\n",
    "print(f\"R2: {r2RF*100:.2f}%\") # Closer to 100% better.\n",
    "print(f\"RMSE: {rmseRF}\") # Closer to 0 better. Useful if big overestimations/costs are a big issue for example. (Be careful with outliers)\n",
    "print(f\"MAE: {maeRF}\") # Closer to 0 better. More generalized, doesn't consider big underestimations or overestimations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "2061baf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 01:45:30,234] A new study created in memory with name: no-name-7e991fb7-00fe-42e3-8573-4aa7fc0eb4bb\n",
      "[I 2025-04-24 01:45:36,392] Trial 0 finished with value: -0.1267659515196566 and parameters: {'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.1699381481911377, 'subsample': 0.9594407245226749, 'colsample_bytree': 0.9280491669635962}. Best is trial 0 with value: -0.1267659515196566.\n",
      "[I 2025-04-24 01:45:42,685] Trial 1 finished with value: -0.12556062305225577 and parameters: {'n_estimators': 190, 'max_depth': 4, 'learning_rate': 0.172294832971713, 'subsample': 0.8449361960226623, 'colsample_bytree': 0.565334405501966}. Best is trial 1 with value: -0.12556062305225577.\n",
      "[I 2025-04-24 01:45:48,495] Trial 2 finished with value: -0.1281094142730414 and parameters: {'n_estimators': 186, 'max_depth': 3, 'learning_rate': 0.17091524704466807, 'subsample': 0.8955878548309084, 'colsample_bytree': 0.7038479005299306}. Best is trial 1 with value: -0.12556062305225577.\n",
      "[I 2025-04-24 01:45:54,171] Trial 3 finished with value: -0.11654520503138721 and parameters: {'n_estimators': 185, 'max_depth': 4, 'learning_rate': 0.16302341369680007, 'subsample': 0.563556754075879, 'colsample_bytree': 0.7244825411846245}. Best is trial 3 with value: -0.11654520503138721.\n",
      "[I 2025-04-24 01:45:59,554] Trial 4 finished with value: -0.12486863008267646 and parameters: {'n_estimators': 186, 'max_depth': 3, 'learning_rate': 0.16480521498282985, 'subsample': 0.6350785607069571, 'colsample_bytree': 0.8005769862774611}. Best is trial 3 with value: -0.11654520503138721.\n",
      "[I 2025-04-24 01:46:05,582] Trial 5 finished with value: -0.1287176822789588 and parameters: {'n_estimators': 186, 'max_depth': 4, 'learning_rate': 0.1928040236648001, 'subsample': 0.7629533453588038, 'colsample_bytree': 0.6499405471325662}. Best is trial 3 with value: -0.11654520503138721.\n",
      "[I 2025-04-24 01:46:10,759] Trial 6 finished with value: -0.11692821864651477 and parameters: {'n_estimators': 188, 'max_depth': 3, 'learning_rate': 0.1950148746615503, 'subsample': 0.5075002195062974, 'colsample_bytree': 0.9629176651912138}. Best is trial 3 with value: -0.11654520503138721.\n",
      "[I 2025-04-24 01:46:15,486] Trial 7 finished with value: -0.12976530413079607 and parameters: {'n_estimators': 185, 'max_depth': 3, 'learning_rate': 0.1752692929901242, 'subsample': 0.9631747468452161, 'colsample_bytree': 0.7079758176916477}. Best is trial 3 with value: -0.11654520503138721.\n",
      "[I 2025-04-24 01:46:20,142] Trial 8 finished with value: -0.11631307457905507 and parameters: {'n_estimators': 185, 'max_depth': 3, 'learning_rate': 0.17622895421769558, 'subsample': 0.5457197637760423, 'colsample_bytree': 0.7408361682846605}. Best is trial 8 with value: -0.11631307457905507.\n",
      "[I 2025-04-24 01:46:24,861] Trial 9 finished with value: -0.113454068614812 and parameters: {'n_estimators': 190, 'max_depth': 3, 'learning_rate': 0.1763652830983176, 'subsample': 0.6448873776210122, 'colsample_bytree': 0.8069956917927652}. Best is trial 9 with value: -0.113454068614812.\n",
      "[I 2025-04-24 01:46:30,881] Trial 10 finished with value: -0.11052202448563339 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.15176633177118767, 'subsample': 0.64687340141167, 'colsample_bytree': 0.8195378912496598}. Best is trial 10 with value: -0.11052202448563339.\n",
      "[I 2025-04-24 01:46:37,002] Trial 11 finished with value: -0.10688149567782557 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.15051886472949882, 'subsample': 0.6635920884596193, 'colsample_bytree': 0.8702433747793537}. Best is trial 11 with value: -0.10688149567782557.\n",
      "[I 2025-04-24 01:46:43,167] Trial 12 finished with value: -0.1117757196130523 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.1530099399180464, 'subsample': 0.689506467270455, 'colsample_bytree': 0.8683278498126366}. Best is trial 11 with value: -0.10688149567782557.\n",
      "[I 2025-04-24 01:46:49,228] Trial 13 finished with value: -0.1223974213276849 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.15013786141798785, 'subsample': 0.7446755355808186, 'colsample_bytree': 0.8900773073125953}. Best is trial 11 with value: -0.10688149567782557.\n",
      "[I 2025-04-24 01:46:55,257] Trial 14 finished with value: -0.11704528651751786 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.1576369194980351, 'subsample': 0.6054787615127617, 'colsample_bytree': 0.9934768673646326}. Best is trial 11 with value: -0.10688149567782557.\n",
      "[I 2025-04-24 01:47:01,348] Trial 15 finished with value: -0.11807389851520902 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.1864762862730711, 'subsample': 0.7228306932721678, 'colsample_bytree': 0.8296633895630431}. Best is trial 11 with value: -0.10688149567782557.\n",
      "[I 2025-04-24 01:47:07,313] Trial 16 finished with value: -0.1272727533902521 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.15750084413878793, 'subsample': 0.7930503041820085, 'colsample_bytree': 0.5000612106650146}. Best is trial 11 with value: -0.10688149567782557.\n",
      "[I 2025-04-24 01:47:13,275] Trial 17 finished with value: -0.115217949363972 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.1565954121490501, 'subsample': 0.6748961980637703, 'colsample_bytree': 0.8912083486777962}. Best is trial 11 with value: -0.10688149567782557.\n",
      "[I 2025-04-24 01:47:19,334] Trial 18 finished with value: -0.11119952704843883 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.16194877990118928, 'subsample': 0.6047939258441761, 'colsample_bytree': 0.8400120667344765}. Best is trial 11 with value: -0.10688149567782557.\n",
      "[I 2025-04-24 01:47:24,709] Trial 19 finished with value: -0.12274444385765841 and parameters: {'n_estimators': 188, 'max_depth': 4, 'learning_rate': 0.1503355297535008, 'subsample': 0.8301471181165814, 'colsample_bytree': 0.7840825104995115}. Best is trial 11 with value: -0.10688149567782557.\n",
      "[I 2025-04-24 01:47:30,623] Trial 20 finished with value: -0.1221142998094561 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.18415041116978842, 'subsample': 0.674661681162987, 'colsample_bytree': 0.6406201619754381}. Best is trial 11 with value: -0.10688149567782557.\n",
      "[I 2025-04-24 01:47:36,518] Trial 21 finished with value: -0.10545640654578001 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.16335925035953336, 'subsample': 0.5819146694885107, 'colsample_bytree': 0.8563349963684592}. Best is trial 21 with value: -0.10545640654578001.\n",
      "[I 2025-04-24 01:47:42,598] Trial 22 finished with value: -0.10001354640122928 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.15465742104469532, 'subsample': 0.5738358791228791, 'colsample_bytree': 0.9397181543571947}. Best is trial 22 with value: -0.10001354640122928.\n",
      "[I 2025-04-24 01:47:48,614] Trial 23 finished with value: -0.10958156272785802 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.1669508476136087, 'subsample': 0.5659823319521629, 'colsample_bytree': 0.948262077801172}. Best is trial 22 with value: -0.10001354640122928.\n",
      "[I 2025-04-24 01:47:54,209] Trial 24 finished with value: -0.11142910189622088 and parameters: {'n_estimators': 190, 'max_depth': 4, 'learning_rate': 0.1582405420958747, 'subsample': 0.5154259609759814, 'colsample_bytree': 0.9172565042181732}. Best is trial 22 with value: -0.10001354640122928.\n",
      "[I 2025-04-24 01:47:59,931] Trial 25 finished with value: -0.10660272090926796 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.15478299990107128, 'subsample': 0.5908260569984151, 'colsample_bytree': 0.9971381221819623}. Best is trial 22 with value: -0.10001354640122928.\n",
      "[I 2025-04-24 01:48:05,409] Trial 26 finished with value: -0.10706000939970624 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.16032829390052555, 'subsample': 0.5885618204291335, 'colsample_bytree': 0.994946605802553}. Best is trial 22 with value: -0.10001354640122928.\n",
      "[I 2025-04-24 01:48:10,524] Trial 27 finished with value: -0.11402526814607014 and parameters: {'n_estimators': 189, 'max_depth': 4, 'learning_rate': 0.15433802682136824, 'subsample': 0.5004558806243148, 'colsample_bytree': 0.9542366839759314}. Best is trial 22 with value: -0.10001354640122928.\n",
      "[I 2025-04-24 01:48:16,021] Trial 28 finished with value: -0.10598654701568203 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.1674389556780525, 'subsample': 0.5373451555710229, 'colsample_bytree': 0.9986599720373791}. Best is trial 22 with value: -0.10001354640122928.\n",
      "[I 2025-04-24 01:48:21,343] Trial 29 finished with value: -0.10250835694346239 and parameters: {'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.16735322688713722, 'subsample': 0.5512851817235421, 'colsample_bytree': 0.9195676824351812}. Best is trial 22 with value: -0.10001354640122928.\n",
      "[I 2025-04-24 01:48:26,571] Trial 30 finished with value: -0.11493095640849185 and parameters: {'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.18137498878177058, 'subsample': 0.7112423995042396, 'colsample_bytree': 0.9204963427249127}. Best is trial 22 with value: -0.10001354640122928.\n",
      "[I 2025-04-24 01:48:31,623] Trial 31 finished with value: -0.10213623560631786 and parameters: {'n_estimators': 188, 'max_depth': 4, 'learning_rate': 0.1684444832631437, 'subsample': 0.5429905798768734, 'colsample_bytree': 0.9325403998885683}. Best is trial 22 with value: -0.10001354640122928.\n",
      "[I 2025-04-24 01:48:36,600] Trial 32 finished with value: -0.10157695212025979 and parameters: {'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.16763363195519917, 'subsample': 0.5397245006168253, 'colsample_bytree': 0.9189152746486307}. Best is trial 22 with value: -0.10001354640122928.\n",
      "[I 2025-04-24 01:48:41,381] Trial 33 finished with value: -0.09675346297724867 and parameters: {'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.171971700216515, 'subsample': 0.5421698858675146, 'colsample_bytree': 0.9030654629335378}. Best is trial 33 with value: -0.09675346297724867.\n",
      "[I 2025-04-24 01:48:46,304] Trial 34 finished with value: -0.12267266254730051 and parameters: {'n_estimators': 186, 'max_depth': 4, 'learning_rate': 0.17336677945325984, 'subsample': 0.917875229984698, 'colsample_bytree': 0.8973657850100927}. Best is trial 33 with value: -0.09675346297724867.\n",
      "[I 2025-04-24 01:48:51,757] Trial 35 finished with value: -0.12536353755152232 and parameters: {'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.17158110106765564, 'subsample': 0.6226523066041837, 'colsample_bytree': 0.9566731413689527}. Best is trial 33 with value: -0.09675346297724867.\n",
      "[I 2025-04-24 01:48:57,116] Trial 36 finished with value: -0.11304440984057025 and parameters: {'n_estimators': 186, 'max_depth': 4, 'learning_rate': 0.17858254171169005, 'subsample': 0.5301457923545787, 'colsample_bytree': 0.9415592327997231}. Best is trial 33 with value: -0.09675346297724867.\n",
      "[I 2025-04-24 01:49:03,363] Trial 37 finished with value: -0.09542549487919749 and parameters: {'n_estimators': 188, 'max_depth': 4, 'learning_rate': 0.169647227120005, 'subsample': 0.5606818367361254, 'colsample_bytree': 0.9031277598760848}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:49:09,819] Trial 38 finished with value: -0.119538413996316 and parameters: {'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.16471957984886137, 'subsample': 0.9920650490344509, 'colsample_bytree': 0.7740957360495382}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:49:15,147] Trial 39 finished with value: -0.12927338728527943 and parameters: {'n_estimators': 186, 'max_depth': 4, 'learning_rate': 0.18991590814510104, 'subsample': 0.5688775819553554, 'colsample_bytree': 0.6491820444758936}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:49:20,316] Trial 40 finished with value: -0.11331127385600699 and parameters: {'n_estimators': 188, 'max_depth': 4, 'learning_rate': 0.1699325130695451, 'subsample': 0.6162607719064199, 'colsample_bytree': 0.8463258484432836}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:49:25,349] Trial 41 finished with value: -0.10921869373044593 and parameters: {'n_estimators': 188, 'max_depth': 4, 'learning_rate': 0.17000970799614204, 'subsample': 0.5240054792618988, 'colsample_bytree': 0.9738480868216131}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:49:30,503] Trial 42 finished with value: -0.0997561712772616 and parameters: {'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.1730326769624935, 'subsample': 0.5476229521969541, 'colsample_bytree': 0.9052345333390098}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:49:35,696] Trial 43 finished with value: -0.09694517913213703 and parameters: {'n_estimators': 186, 'max_depth': 4, 'learning_rate': 0.17946069460876835, 'subsample': 0.5618415076461611, 'colsample_bytree': 0.8976541185328557}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:49:41,008] Trial 44 finished with value: -0.10377669368244799 and parameters: {'n_estimators': 186, 'max_depth': 4, 'learning_rate': 0.18065339225061497, 'subsample': 0.5717466893745611, 'colsample_bytree': 0.8827117594025917}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:49:45,728] Trial 45 finished with value: -0.10482059116222428 and parameters: {'n_estimators': 185, 'max_depth': 3, 'learning_rate': 0.17335495848854876, 'subsample': 0.5131468155235928, 'colsample_bytree': 0.9010841053650964}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:49:50,712] Trial 46 finished with value: -0.12272697780973432 and parameters: {'n_estimators': 185, 'max_depth': 3, 'learning_rate': 0.17794421292886123, 'subsample': 0.628441847583012, 'colsample_bytree': 0.8642980355959562}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:49:57,166] Trial 47 finished with value: -0.09814727562424405 and parameters: {'n_estimators': 186, 'max_depth': 4, 'learning_rate': 0.17470290063486482, 'subsample': 0.5551823027676763, 'colsample_bytree': 0.9681531954232561}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:50:03,078] Trial 48 finished with value: -0.1190609603282033 and parameters: {'n_estimators': 186, 'max_depth': 4, 'learning_rate': 0.17487354452691953, 'subsample': 0.5998509911998339, 'colsample_bytree': 0.9669476713534269}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:50:10,470] Trial 49 finished with value: -0.11036452006393198 and parameters: {'n_estimators': 186, 'max_depth': 4, 'learning_rate': 0.1823502094614968, 'subsample': 0.6449534652934868, 'colsample_bytree': 0.8107501300173197}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:50:16,538] Trial 50 finished with value: -0.12126569853650478 and parameters: {'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.1792842346729758, 'subsample': 0.5500227364477781, 'colsample_bytree': 0.6800771026078176}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:50:22,722] Trial 51 finished with value: -0.11725662736508666 and parameters: {'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.17515408517782635, 'subsample': 0.5642273297296619, 'colsample_bytree': 0.9745612892598289}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:50:29,859] Trial 52 finished with value: -0.10808553863114793 and parameters: {'n_estimators': 186, 'max_depth': 4, 'learning_rate': 0.17712285634155667, 'subsample': 0.5039030768233709, 'colsample_bytree': 0.8782926904974453}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:50:36,077] Trial 53 finished with value: -0.12728774935185982 and parameters: {'n_estimators': 186, 'max_depth': 4, 'learning_rate': 0.1863459710075285, 'subsample': 0.5831998639553113, 'colsample_bytree': 0.936979112321626}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:50:41,766] Trial 54 finished with value: -0.09674271833005169 and parameters: {'n_estimators': 185, 'max_depth': 4, 'learning_rate': 0.17236359738983079, 'subsample': 0.5590846016151699, 'colsample_bytree': 0.9043552616352555}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:50:47,795] Trial 55 finished with value: -0.0982716832048042 and parameters: {'n_estimators': 185, 'max_depth': 4, 'learning_rate': 0.17272391103408777, 'subsample': 0.5258391940000858, 'colsample_bytree': 0.9001293391713993}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:50:54,339] Trial 56 finished with value: -0.10813773758476257 and parameters: {'n_estimators': 185, 'max_depth': 4, 'learning_rate': 0.17171045129850518, 'subsample': 0.5282844222673035, 'colsample_bytree': 0.8291557054074283}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:51:00,333] Trial 57 finished with value: -0.1216953796715868 and parameters: {'n_estimators': 185, 'max_depth': 4, 'learning_rate': 0.1757468693400455, 'subsample': 0.6032089710608608, 'colsample_bytree': 0.5978445920979962}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:51:06,288] Trial 58 finished with value: -0.11486040379384813 and parameters: {'n_estimators': 185, 'max_depth': 4, 'learning_rate': 0.16897567439162264, 'subsample': 0.7705176591365726, 'colsample_bytree': 0.8504242824718389}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:51:13,061] Trial 59 finished with value: -0.10879286735234377 and parameters: {'n_estimators': 185, 'max_depth': 4, 'learning_rate': 0.17413119308903183, 'subsample': 0.5627355109639399, 'colsample_bytree': 0.7506807033921239}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:51:20,081] Trial 60 finished with value: -0.1222568379393639 and parameters: {'n_estimators': 185, 'max_depth': 4, 'learning_rate': 0.16521055321013883, 'subsample': 0.8418538850323721, 'colsample_bytree': 0.8711374319042393}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:51:26,264] Trial 61 finished with value: -0.10002117557910353 and parameters: {'n_estimators': 186, 'max_depth': 4, 'learning_rate': 0.1723214562315938, 'subsample': 0.5532338900820714, 'colsample_bytree': 0.9067627110248437}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:51:32,174] Trial 62 finished with value: -0.1051576635120219 and parameters: {'n_estimators': 185, 'max_depth': 4, 'learning_rate': 0.17075239378114135, 'subsample': 0.520331845311748, 'colsample_bytree': 0.907095633319098}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:51:38,943] Trial 63 finished with value: -0.11280555030662862 and parameters: {'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.1766768986379455, 'subsample': 0.656021247415424, 'colsample_bytree': 0.8791331835471862}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:51:44,827] Trial 64 finished with value: -0.11671624675356537 and parameters: {'n_estimators': 188, 'max_depth': 4, 'learning_rate': 0.17952875099094115, 'subsample': 0.5001453685882944, 'colsample_bytree': 0.981415176962647}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:51:51,240] Trial 65 finished with value: -0.10483037245661583 and parameters: {'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.17277028947372614, 'subsample': 0.586672906657346, 'colsample_bytree': 0.8939612832749475}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:51:56,721] Trial 66 finished with value: -0.11348784499494044 and parameters: {'n_estimators': 185, 'max_depth': 4, 'learning_rate': 0.1981997690957725, 'subsample': 0.5553110258856728, 'colsample_bytree': 0.9258643902313068}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:52:01,841] Trial 67 finished with value: -0.12676421838866142 and parameters: {'n_estimators': 186, 'max_depth': 3, 'learning_rate': 0.1843142495503172, 'subsample': 0.6139039277262531, 'colsample_bytree': 0.8269234028486117}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:52:07,342] Trial 68 finished with value: -0.11225660038007726 and parameters: {'n_estimators': 186, 'max_depth': 4, 'learning_rate': 0.17042359225248532, 'subsample': 0.535815506899843, 'colsample_bytree': 0.7922668650808447}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:52:12,755] Trial 69 finished with value: -0.10902825170442176 and parameters: {'n_estimators': 188, 'max_depth': 4, 'learning_rate': 0.1662827577529301, 'subsample': 0.5208974941165221, 'colsample_bytree': 0.9545479436997366}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:52:18,108] Trial 70 finished with value: -0.10361887441282258 and parameters: {'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.17453195470348526, 'subsample': 0.5780714874468584, 'colsample_bytree': 0.8545585889234845}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:52:23,840] Trial 71 finished with value: -0.10616498859234044 and parameters: {'n_estimators': 185, 'max_depth': 4, 'learning_rate': 0.16106138756507085, 'subsample': 0.5417095097283472, 'colsample_bytree': 0.9335636099144029}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:52:29,439] Trial 72 finished with value: -0.1010702540321828 and parameters: {'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.17745529286802575, 'subsample': 0.596005930916909, 'colsample_bytree': 0.9082038258312094}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:52:36,063] Trial 73 finished with value: -0.1090344467546364 and parameters: {'n_estimators': 186, 'max_depth': 4, 'learning_rate': 0.16877335235483118, 'subsample': 0.5729499807819743, 'colsample_bytree': 0.9519319111582334}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:52:42,211] Trial 74 finished with value: -0.10192256693979844 and parameters: {'n_estimators': 185, 'max_depth': 4, 'learning_rate': 0.17588924409331383, 'subsample': 0.5548924782930755, 'colsample_bytree': 0.8890332273560391}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:52:48,870] Trial 75 finished with value: -0.11726329363311536 and parameters: {'n_estimators': 190, 'max_depth': 4, 'learning_rate': 0.18339685016386198, 'subsample': 0.5318378403091666, 'colsample_bytree': 0.9419552854425928}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:52:55,865] Trial 76 finished with value: -0.12447695368835124 and parameters: {'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.1799301147747294, 'subsample': 0.8780633949619499, 'colsample_bytree': 0.9826819507312397}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:53:01,505] Trial 77 finished with value: -0.10885789224708495 and parameters: {'n_estimators': 189, 'max_depth': 3, 'learning_rate': 0.17351834986291342, 'subsample': 0.5105169232260243, 'colsample_bytree': 0.9228831998125249}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:53:08,637] Trial 78 finished with value: -0.11035432971489971 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.15903205720718233, 'subsample': 0.6133806959249969, 'colsample_bytree': 0.9658841213859175}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:53:14,698] Trial 79 finished with value: -0.10199849545379025 and parameters: {'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.16324196576538502, 'subsample': 0.5800816075153933, 'colsample_bytree': 0.9146320777808367}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:53:20,944] Trial 80 finished with value: -0.11201891260173964 and parameters: {'n_estimators': 188, 'max_depth': 4, 'learning_rate': 0.1712131135817697, 'subsample': 0.6316666379154319, 'colsample_bytree': 0.8668680504285895}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:53:27,824] Trial 81 finished with value: -0.10137982386800819 and parameters: {'n_estimators': 186, 'max_depth': 4, 'learning_rate': 0.1718831464177084, 'subsample': 0.5551200810147343, 'colsample_bytree': 0.9046141663865017}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:53:33,986] Trial 82 finished with value: -0.10438977385443064 and parameters: {'n_estimators': 186, 'max_depth': 4, 'learning_rate': 0.1727818127259403, 'subsample': 0.546214505096889, 'colsample_bytree': 0.8967127122854275}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:53:40,208] Trial 83 finished with value: -0.10492729533116973 and parameters: {'n_estimators': 186, 'max_depth': 4, 'learning_rate': 0.16915277835944312, 'subsample': 0.5633120675109266, 'colsample_bytree': 0.9413269902440048}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:53:46,099] Trial 84 finished with value: -0.1141080295573097 and parameters: {'n_estimators': 186, 'max_depth': 4, 'learning_rate': 0.15261275966941987, 'subsample': 0.5322332266880224, 'colsample_bytree': 0.9264920331189519}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:53:51,463] Trial 85 finished with value: -0.10347222007098444 and parameters: {'n_estimators': 185, 'max_depth': 4, 'learning_rate': 0.17822363018059784, 'subsample': 0.517807584088003, 'colsample_bytree': 0.9093757161702805}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:53:56,731] Trial 86 finished with value: -0.10897609842464565 and parameters: {'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.16591611498522568, 'subsample': 0.5937296095609471, 'colsample_bytree': 0.8838529566548359}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:54:02,156] Trial 87 finished with value: -0.12696728112528274 and parameters: {'n_estimators': 186, 'max_depth': 4, 'learning_rate': 0.1815605454546091, 'subsample': 0.5573833515376126, 'colsample_bytree': 0.5095932848426786}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:54:07,624] Trial 88 finished with value: -0.10540235056428462 and parameters: {'n_estimators': 190, 'max_depth': 4, 'learning_rate': 0.17396462347201277, 'subsample': 0.543935409467772, 'colsample_bytree': 0.8408930876433365}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:54:12,986] Trial 89 finished with value: -0.1141516878441025 and parameters: {'n_estimators': 185, 'max_depth': 4, 'learning_rate': 0.15642084523377467, 'subsample': 0.5792816378611965, 'colsample_bytree': 0.9616628072674055}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:54:18,351] Trial 90 finished with value: -0.11758251651253962 and parameters: {'n_estimators': 189, 'max_depth': 4, 'learning_rate': 0.19072369500375708, 'subsample': 0.7031907201448105, 'colsample_bytree': 0.8589554232605452}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:54:23,621] Trial 91 finished with value: -0.09611388766451319 and parameters: {'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.17497101534690074, 'subsample': 0.5738981633246601, 'colsample_bytree': 0.9106668708961607}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:54:28,969] Trial 92 finished with value: -0.10288310828625372 and parameters: {'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.17654849153986027, 'subsample': 0.5461496068408697, 'colsample_bytree': 0.8747499508832692}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:54:34,289] Trial 93 finished with value: -0.11353499353888234 and parameters: {'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.17489893624427347, 'subsample': 0.5699711981844134, 'colsample_bytree': 0.9329501012790826}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:54:39,698] Trial 94 finished with value: -0.10454718132824167 and parameters: {'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.17221823619620996, 'subsample': 0.6031513135521035, 'colsample_bytree': 0.8970958666632382}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:54:45,027] Trial 95 finished with value: -0.1043463389246875 and parameters: {'n_estimators': 186, 'max_depth': 4, 'learning_rate': 0.1756243034423951, 'subsample': 0.525258189236997, 'colsample_bytree': 0.9495951804818976}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:54:50,445] Trial 96 finished with value: -0.12547887767482635 and parameters: {'n_estimators': 188, 'max_depth': 4, 'learning_rate': 0.1698904838994524, 'subsample': 0.8149601421305629, 'colsample_bytree': 0.9115210353332905}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:54:55,835] Trial 97 finished with value: -0.10198482322299465 and parameters: {'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.16771745093778728, 'subsample': 0.5127234984997692, 'colsample_bytree': 0.8878087658296301}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:55:01,175] Trial 98 finished with value: -0.1224484169066331 and parameters: {'n_estimators': 186, 'max_depth': 4, 'learning_rate': 0.1725697340351138, 'subsample': 0.5876105037333581, 'colsample_bytree': 0.9822855235194659}. Best is trial 37 with value: -0.09542549487919749.\n",
      "[I 2025-04-24 01:55:06,553] Trial 99 finished with value: -0.10366515432998238 and parameters: {'n_estimators': 185, 'max_depth': 4, 'learning_rate': 0.17084298996970895, 'subsample': 0.5625390746414465, 'colsample_bytree': 0.9245723074770084}. Best is trial 37 with value: -0.09542549487919749.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'n_estimators': 188, 'max_depth': 4, 'learning_rate': 0.169647227120005, 'subsample': 0.5606818367361254, 'colsample_bytree': 0.9031277598760848}\n"
     ]
    }
   ],
   "source": [
    "# Study creation and optimization process to find best parameters with optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(bestParamsEstimatorXGBR(preprocessor, X_train, y_train), n_trials=100)\n",
    "\n",
    "print(\"Best parameters found:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0940c5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of XGBRegressor with the best parameters found by optuna\n",
    "model = XGBRegressor(\n",
    "    n_estimators = study.best_params['n_estimators'],\n",
    "    max_depth = study.best_params['max_depth'],\n",
    "    learning_rate = study.best_params['learning_rate'],\n",
    "    subsample = study.best_params['subsample'],\n",
    "    colsample_bytree = study.best_params['colsample_bytree']\n",
    "    )\n",
    "\n",
    "# Pipeline creation with model with best parameters\n",
    "regressor = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Fitting and training model with train dataset\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions for valid dataset with random forest regressor model\n",
    "predictions = regressor.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "0bc5abac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 84.04%\n",
      "RMSE: 0.33878002398320384\n",
      "MAE: 0.03603258270885044\n"
     ]
    }
   ],
   "source": [
    "# Calculated error metrics for R2, RMSE and MAE\n",
    "rmseRF = np.sqrt(mean_squared_error(y_valid, predictions))\n",
    "maeRF = mean_absolute_error(y_valid, predictions)\n",
    "r2RF = r2_score(y_valid, predictions)\n",
    "\n",
    "print(f\"R2: {r2RF*100:.2f}%\") # Closer to 100% better.\n",
    "print(f\"RMSE: {rmseRF}\") # Closer to 0 better. Useful if big overestimations/costs are a big issue for example. (Be careful with outliers)\n",
    "print(f\"MAE: {maeRF}\") # Closer to 0 better. More generalized, doesn't consider big underestimations or overestimations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
